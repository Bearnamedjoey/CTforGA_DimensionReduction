# very simple dendrogram
plot(hc,hang = -1,cex=0.3)
library(factoextra)
fviz_nbclust(dataToCluster,
hcut,
diss=distancesData,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "agnes")
library(factoextra)
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "agnes")
fviz_nbclust(dataToCluster,
hcut,
diss=distancesData,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
fviz_nbclust(dataToCluster,
hcut,
diss=distancesData,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
?hcut
fviz_silhouette(res.agnes)
NumberOfClusterDesired=4
#library(factoextra)
res.agnes= hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2")
# Hierarchical technique- divisive approach
res.diana= hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2")
fromPy$agn=as.factor(res.agnes$cluster)
fromPy$dia=as.factor(res.diana$cluster)
aggregate(data=fromPy,
Overallscore~agn,
FUN=mean)
aggregate(data=fromPy,
Overallscore~dia,
FUN=mean)
library(dplyr)
fromPy$agn=dplyr::recode_factor(fromPy$agn,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$dia=dplyr::recode_factor(fromPy$dia,
`1` = '4',`2`='3',`3`='2',`4`='1')
library(dplyr)
fromPy$agn=dplyr::recode_factor(fromPy$agn,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$dia=dplyr::recode_factor(fromPy$dia,
`1` = '4',`2`='3',`3`='2',`4`='1')
fviz_silhouette(res.agnes)
library(factoextra)
fviz_silhouette(res.diana)
agnEval=data.frame(res.agnes$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
agnPoor=rownames(agnEval[agnEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
bad_Clus=as.data.frame(qpcR:::cbind.na(sort(agnPoor),
sort(diaPoor)))
names(bad_Clus)=c("agn","dia")
bad_Clus
base= ggplot(data=fromPy,
aes(x=dim1, y=dim2,
label=Country))
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
library(ggpubr)
ggarrange(agnPlot, diaPlot,ncol = 2,common.legend = T)
# If name of country in black list, use it, else get rid of it
LABELdia=ifelse(fromPy$Country%in%diaPoor,fromPy$Country,"")
LABELagn=ifelse(fromPy$Country%in%agnPoor,fromPy$Country,"")
library(ggrepel)
diaPlot + geom_text_repel(aes(label=LABELdia),max.overlaps = 50,min.segment.length = unit(0, 'lines'))
agnPlot + geom_text_repel(aes(label=LABELagn),max.overlaps = 50,min.segment.length = unit(0, 'lines'))
fviz_dend(res.agnes,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "AGNES approach")
fviz_dend(res.diana,k=NumberOfClusterDesired, cex = 0.45, horiz = T,main = "DIANA approach")
fviz_dend(res.agnes,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach")
fviz_dend(res.agnes,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach") + guides(<scale> = "none")
fviz_dend(res.agnes,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach")
fviz_dend(res.diana,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "DIANA approach")
table(fromPy$Regimetype,fromPy$agn)
table(fromPy$Regimetype,fromPy$dia)
dataForFA=dataToCluster
View(dataToCluster)
View(dataForFA)
?polycor::hetcor
library(polycor)
corMatrix=polycor::hetcor(dataForFA)$correlations
library(ggcorrplot)
ggcorrplot(corMatrix,
type = "lower") +
theme(axis.text.x  = element_text(size = 5),
axis.text.y  = element_text(size = 5))
library(psych)
psych::KMO(corMatrix)
library(psych)
psych::KMO(corMatrix)
cortest.bartlett(corMatrix,n=nrow(dataForFA))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(dataForFA, fa = 'fa',correct = T,plot = F)
library(GPArotation)
resfa <- fa(dataForFA,
nfactors = 2,
cor = 'mixed',
rotate = "varimax",
fm="minres")
print(resfa$loadings)
sort(resfa$communality)
sort(resfa$complexity)
# esta es:
library(polycor)
corMatrix2=polycor::hetcor(dataForFA)$correlations
library(psych)
psych::KMO(corMatrix)
library(psych)
psych::KMO(corMatrix2)
cortest.bartlett(corMatrix2,n=nrow(dataForFA))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix2)
ps=c("P1StateLegitimacy","P2PublicServices","P3HumanRights")
notPs=setdiff(names(dataForFA),ps)
dataForFA=dataForFA[,notPs]
# esta es:
library(polycor)
corMatrix2=polycor::hetcor(dataForFA)$correlations
# clean memory
rm(list = ls())
# link to data file
link='https://github.com/EvansDataScience/CTforGA_integrating/raw/main/demo_fragile.RDS'
# a RDS file from the web needs:
myFile=url(link)
# reading in the data:
fromPy=readRDS(file = myFile)
# reset indexes to R paradigm:
row.names(fromPy)=NULL
# check data types
str(fromPy)
# select variables
dataToCluster=fromPy[,-c(1:3,9)]
#save the country names as the row index
row.names(dataToCluster)=fromPy$Country
summary(dataToCluster)
boxplot(dataToCluster,horizontal = T, las=2,cex.axis=0.4)
set.seed(999)
library(cluster)
distanceMatrix=daisy(x=dataToCluster, metric = "gower")
projectedData = cmdscale(distanceMatrix, k=2)
# save coordinates to original data frame:
fromPy$dim1 = projectedData[,1]
fromPy$dim2 = projectedData[,2]
# see some:
fromPy[,c('dim1','dim2')][1:10,]
library(ggplot2)
base= ggplot(data=fromPy,
aes(x=dim1, y=dim2,
label=Country))
base + geom_text(size=2)
# prepare hierarchical cluster
hc = hclust(distanceMatrix)
# very simple dendrogram
plot(hc,hang = -1,cex=0.3)
library(factoextra)
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "agnes")
fviz_nbclust(dataToCluster,
hcut,
diss=distanceMatrix,
method = "gap_stat",
k.max = 10,
verbose = F,
hc_func = "diana")
NumberOfClusterDesired=4
#library(factoextra)
res.agnes= hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='agnes',
hc_method = "ward.D2")
# Hierarchical technique- divisive approach
res.diana= hcut(distanceMatrix,
k = NumberOfClusterDesired,
isdiss=TRUE,
hc_func='diana',
hc_method = "ward.D2")
fromPy$agn=as.factor(res.agnes$cluster)
fromPy$dia=as.factor(res.diana$cluster)
aggregate(data=fromPy,
Overallscore~agn,
FUN=mean)
aggregate(data=fromPy,
Overallscore~dia,
FUN=mean)
library(dplyr)
fromPy$agn=dplyr::recode_factor(fromPy$agn,
`1` = '4',`2`='3',`3`='2',`4`='1')
fromPy$dia=dplyr::recode_factor(fromPy$dia,
`1` = '4',`2`='3',`3`='2',`4`='1')
fviz_silhouette(res.agnes)
library(factoextra)
fviz_silhouette(res.diana)
agnEval=data.frame(res.agnes$silinfo$widths)
diaEval=data.frame(res.diana$silinfo$widths)
agnPoor=rownames(agnEval[agnEval$sil_width<0,])
diaPoor=rownames(diaEval[diaEval$sil_width<0,])
library("qpcR")
bad_Clus=as.data.frame(qpcR:::cbind.na(sort(agnPoor),
sort(diaPoor)))
names(bad_Clus)=c("agn","dia")
bad_Clus
base= ggplot(data=fromPy,
aes(x=dim1, y=dim2,
label=Country))
agnPlot=base + labs(title = "AGNES") + geom_point(size=2,
aes(color=agn),
show.legend = T)
diaPlot=base + labs(title = "DIANA") + geom_point(size=2,
aes(color=dia),
show.legend = T)
library(ggpubr)
ggarrange(agnPlot, diaPlot,ncol = 2,common.legend = T)
# If name of country in black list, use it, else get rid of it
LABELdia=ifelse(fromPy$Country%in%diaPoor,fromPy$Country,"")
LABELagn=ifelse(fromPy$Country%in%agnPoor,fromPy$Country,"")
library(ggrepel)
diaPlot=diaPlot +
geom_text_repel(aes(label=LABELdia),
max.overlaps=50,
min.segment.length =unit(0,'lines'))
agnPlot= agnPlot +
geom_text_repel(aes(label=LABELagn),
max.overlaps = 50,
min.segment.length = unit(0, 'lines'))
ggarrange(agnPlot,
diaPlot,
ncol = 2,
common.legend = T)
fviz_dend(res.agnes,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "AGNES approach")
fviz_dend(res.diana,
k=NumberOfClusterDesired,
cex = 0.45,
horiz = T,
main = "DIANA approach")
table(fromPy$Regimetype,fromPy$agn)
table(fromPy$Regimetype,fromPy$dia)
dataForFA=dataToCluster
library(polycor)
corMatrix=polycor::hetcor(dataForFA)$correlations
library(ggcorrplot)
ggcorrplot(corMatrix,
type = "lower") +
theme(axis.text.x  = element_text(size = 5),
axis.text.y  = element_text(size = 5))
library(psych)
psych::KMO(corMatrix)
# is identity matrix?
cortest.bartlett(corMatrix,n=nrow(dataForFA))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix)
fa.parallel(dataForFA, fa = 'fa',correct = T,plot = F)
library(GPArotation)
resfa <- fa(dataForFA,
nfactors = 2,
cor = 'mixed',
rotate = "varimax",
fm="minres")
### see results
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa,main = "EFA results")
# The higher the better
sort(resfa$communality)
# closer to 2, 3, etc?
# closer to zero?
sort(resfa$complexity)
ps=c("P1StateLegitimacy","P2PublicServices","P3HumanRights")
notPs=setdiff(names(dataForFA),ps)
dataForFA2=dataForFA[,notPs]
# esta es:
library(polycor)
corMatrix2=polycor::hetcor(dataForFA2)$correlations
library(psych)
psych::KMO(corMatrix2)
cortest.bartlett(corMatrix2,n=nrow(dataForFA2))$p.value>0.05
library(matrixcalc)
is.singular.matrix(corMatrix2)
fa.parallel(dataForFA2, fa = 'fa',correct = T,plot = F)
library(GPArotation)
resfa <- fa(dataForFA2,
nfactors = 2,
cor = 'mixed',
rotate = "varimax",
fm="minres")
print(resfa$loadings)
print(resfa$loadings,cutoff = 0.5)
fa.diagram(resfa,main = "EFA results")
sort(resfa$complexity)
sort(resfa$communality)
summary(resfa$scores)
library(BBmisc)
efa_scores=normalize(resfa$scores,
method = "range",
margin=2, # by column
range = c(0, 10))
# save the scores in the data
fromPy$Fragile_efa=efa_scores[,1]
fromPy$Demo_efa=efa_scores[,2]
library("ggpubr")
ggscatter(data=fromPy, x = "Overallscore", y = "Demo_efa",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "DemoIndex (original)", ylab = "DemoIndex (efa)")
library("ggpubr")
ggscatter(data=fromPy, x = "Overallscore", y = "Demo_efa",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "DemoIndex (original)", ylab = "DemoIndex (efa)")
ggscatter(data=fromPy, x = "Total", y = "Fragile_efa",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "pearson",
xlab = "FragileIndex (original)", ylab = "FragileIndex (efa)")
link='https://github.com/EvansDataScience/data/raw/master/eduwa.rda'
#getting the data TABLE from the file in the cloud:
load(file=url(link))
# clean memory
rm(list = ls())
link='https://github.com/EvansDataScience/data/raw/master/eduwa.rda'
#getting the data TABLE from the file in the cloud:
load(file=url(link))
# how many unique values
length(unique(eduwa$Reduced.Lunch))
lunchDF=as.data.frame(table(eduwa$Reduced.Lunch))
names(lunchDF)=c("Beneficiaries","Count")
library(ggplot2)
base1=ggplot(data=lunchDF, aes(x=Beneficiaries,Count))
bar1=base1+geom_bar(stat = "identity")
bar1
# sum of reduced lunches given per county
CountyCount_LR=aggregate(data=eduwa,
Reduced.Lunch~County,
FUN=sum)
# sum of reduced lunches given per county
CountyCount_LR=aggregate(data=eduwa,
Reduced.Lunch~County,
FUN=sum)
#see
CountyCount_LR
# order and minus (-) for decreasing
CountyCount_LR=CountyCount_LR[order(-CountyCount_LR$Reduced.Lunch),]
head(CountyCount_LR,10)
CountyCount_LR$Percent=CountyCount_LR$Reduced.Lunch/sum(CountyCount_LR$Reduced.Lunch)
CountyCount_LR$PercentCum=cumsum(CountyCount_LR$Percent)
CountyCount_LR$Reduced.Lunch.Cum=cumsum(CountyCount_LR$Reduced.Lunch)
# see some:
head(CountyCount_LR,20)
base2=ggplot(data=CountyCount_LR,
aes(x=County,Reduced.Lunch.Cum)) + theme_classic()
base3=base2+scale_x_discrete()
bar2=base3  +geom_bar(stat = "identity")
bar2=bar2 + coord_flip()
bar2
# altering previous base3
base3=base2+scale_x_discrete(limits=CountyCount_LR$County)
bar2=base3  +geom_bar(stat = "identity")
bar2=bar2 + coord_flip()
bar2
bar2=base3  +geom_bar(stat = "identity",color='grey90',
aes(fill=PercentCum<0.8),
show.legend = F)
bar2=bar2 + coord_flip()
bar2
# I only need one fill color, that is why I put 'NA":
bar2=bar2 +scale_fill_manual(values=c(NA,"grey90"))
bar2
# this is a condition outside ggplot.
# it says what counties add to 80%
counties80=CountyCount_LR[CountyCount_LR$PercentCum<0.8,"County"]
# now we use that here, to alter the face of text:
bar2=bar2 + theme(axis.text.y = element_text(face=ifelse(CountyCount_LR$County%in%counties80,"bold","plain"),size=9))
bar2
library(ggQC) # install this previously
install.packages("ggQC")
library(ggQC) # install this previously
base4=ggplot(data=CountyCount_LR,
aes(x=County,y=Reduced.Lunch)) + theme_classic()
pare1=base4 + stat_pareto()
pare1
# computing intercepts
interX=length(counties80)
interY=max(CountyCount_LR$Reduced.Lunch.Cum)*0.8
# annotating intercepts
pare2=pare1 + geom_vline(xintercept = interX,
linetype="dashed", color='grey90')
pare2=pare2 + geom_hline(yintercept =interY,
linetype="dashed", color='grey90')
pare2 + theme(axis.text.x = element_text(angle = 30, hjust = 1,face=ifelse(CountyCount_LR$County%in%counties80,"bold","plain")))
summary(eduwa$Reduced.Lunch)
# standard deviation:
sd(eduwa$Reduced.Lunch,na.rm = T)
#ggplot
WIDTH=10
library(ggplot2)
base= ggplot(eduwa,aes(x = Reduced.Lunch))
h1= base + geom_histogram(binwidth = WIDTH)
h1
MEAN=summary(eduwa$Reduced.Lunch)[4]
h1+ geom_vline(xintercept = MEAN)
base= ggplot(eduwa,aes(y = Reduced.Lunch))
b1= base + geom_boxplot()
b1 +coord_flip()
lunchDF=as.data.frame(table(eduwa$Reduced.Lunch))
names(lunchDF)=c("Beneficiaries","Count")
library(ggplot2)
base1=ggplot(data=lunchDF, aes(x=Beneficiaries,Count))
bar1=base1+geom_bar(stat = "identity")
bar1
summary(eduwa$Reduced.Lunch)
# standard deviation:
sd(eduwa$Reduced.Lunch,na.rm = T)
# median absolute deviation:
mad(eduwa$Reduced.Lunch,na.rm = T)
# asymmetry
library(DescTools)
Skew(eduwa$Reduced.Lunch,
na.rm = T,
conf.level = 0.95,
ci.type = "bca",
R=2500)
# asymmetry
library(DescTools)
Skew(eduwa$Reduced.Lunch,
na.rm = T,
conf.level = 0.95,
ci.type = "bca",
R=2500)
# shape
#library(DescTools)
Kurt(eduwa$Reduced.Lunch,
na.rm = T,conf.level = 0.95,
ci.type = "bca",R=2500)
# shape
#library(DescTools)
Kurt(eduwa$Reduced.Lunch,
na.rm = T,conf.level = 0.05,
ci.type = "bca",R=2500)
?Kurt
library(DescTools)
CoefVar(eduwa$Reduced.Lunch,
na.rm = T,
conf.level = 0.95)
library(DescTools)
CoefVar(eduwa$Reduced.Lunch,
na.rm = T,
unbiased=T,
conf.level = 0.95)
library(DescTools)
CoefVar(eduwa$Reduced.Lunch,
na.rm = T,
unbiased=T,
conf.level = 0.95)
